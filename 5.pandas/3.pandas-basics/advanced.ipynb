{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7a33ec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93f463b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## MultiIndex & Hierarchical Data\n",
    "\n",
    "# What is MultiIndex?\n",
    "# MultiIndex = Index with multiple levels (rows or columns).\n",
    "# It lets you work with nested groups.\n",
    "\n",
    "arrays = [\n",
    "    ['A', 'A', 'B', 'B'],\n",
    "    ['cat', 'dog', 'cat', 'dog']\n",
    "]\n",
    "\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('Letter', 'Animal'))\n",
    "df = pd.DataFrame({'Value': [5, 6, 7, 8]}, index=index)  # Now you have two index levels: Letter and Animal.\n",
    "# df = pd.DataFrame({'Value': [5, 6, 7, 8], 'sec_value': [1, 2, 3, 4]}, index=index)\n",
    "df\n",
    "\n",
    "# Accessing MultiIndex Data\n",
    "df.loc['A']\n",
    "df.loc[('A', 'dog')]  # MultiIndex uses tuples when specifying multiple levels.\n",
    "\n",
    "# resetting multi index\n",
    "# df_reset = df.reset_index()\n",
    "# df_reset   # Converts MultiIndex back into flat DataFrame, (letter, animal) will be regular columns\n",
    "\n",
    "# Stacking & Unstacking\n",
    "# ‚Äúpivot‚Äù is Changing the shape of the table ‚Üí making rows become columns or columns become rows.\n",
    "\n",
    "# Unstack ‚Üí Rows ‚Üí Columns\n",
    "df_unstacked = df.unstack()\n",
    "# The second level of the index (Animal) has been pivoted into columns:\n",
    "# cat ‚Üí new column\n",
    "# dog ‚Üí new column\n",
    "# üëâ The table is now wide format.\n",
    "df_unstacked\n",
    "df_unstacked[('Value', 'cat')]\n",
    "\n",
    "# Stack ‚Üí Columns ‚Üí Rows (Reverse)\n",
    "df_stacked = df_unstacked.stack(future_stack=True)  # Back to long format.\n",
    "df_stacked\n",
    "\n",
    "\n",
    "# convert flat DataFrame to MultiIndex\n",
    "df = pd.DataFrame({\n",
    "    'City': ['Cairo', 'London', 'Cairo'],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Score': [85, 90, 78]\n",
    "})\n",
    "\n",
    "# This is flat: single index (0,1,2)\n",
    "\n",
    "# If you set_index:\n",
    "df2 = df.set_index(['City', 'Name'])\n",
    "\n",
    "# Now you can stack/unstack because it's MultiIndex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed242171",
   "metadata": {},
   "source": [
    "- Unstack ‚Üí moves part of the row index ‚Üí into columns (wide format)\n",
    "- Stack ‚Üí moves part of the columns ‚Üí back into row index (long format)\n",
    "\n",
    "üëâ It‚Äôs like reshaping the data horizontally or vertically without changing the data itself.\n",
    "\n",
    "| Function     | What it Does                               | Result |\n",
    "| ------------ | ------------------------------------------ | ------ |\n",
    "| `.unstack()` | Moves one row index level into **columns** | Wide   |\n",
    "| `.stack()`   | Moves one column level into **rows**       | Long   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "47a1a1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alice</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bob</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>charlie</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Score\n",
       "0    alice    410\n",
       "1      bob    430\n",
       "2  charlie    382"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Apply Functions in Pandas\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Score': [85, 90, 78]\n",
    "})\n",
    "\n",
    "# map() ‚Üí Works on Series (one column)\n",
    "df['Name'] = df['Name'].map(str.upper)\n",
    "df['Score'] = df['Score'].map(lambda x: x * 2)\n",
    "\n",
    "# map() on DataFrame (Cell by Cell)\n",
    "df = df.map(lambda x: str(x).lower() if isinstance(x, str) else x)  # This applies the function to every single cell of the DataFrame\n",
    "\n",
    "def add_symbol(x):\n",
    "    return x + 10 if isinstance(x, (int, float)) else x\n",
    "df = df.map(add_symbol)\n",
    "\n",
    "\n",
    "# apply() ‚Üí Works on Series OR DataFrame\n",
    "# Apply on Series\n",
    "df['Score'] = df['Score'].apply(lambda x: x * 2)\n",
    "\n",
    "# Apply on DataFrame row\n",
    "df['Score'] = df.apply(lambda row: row['Score'] + 50, axis=1)  # i have to use axis=1, to indicate that applying on rows\n",
    "\n",
    "# Apply on Columns (One Function per Column) ‚Üí axis=0 (default)\n",
    "df.apply(lambda col: col[0])\n",
    "df.apply(lambda col: col.mean() if col.dtype != 'O' else None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2f15bfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Advanced GroupBy (Nested Grouping + Custom Aggregations)\n",
    "\n",
    "data = {\n",
    "    'Region': ['North', 'North', 'South', 'South', 'South'],\n",
    "    'City': ['Cairo', 'Cairo', 'Aswan', 'Aswan', 'Luxor'],\n",
    "    'Sales': [100, 150, 200, 250, 300]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# This creates a MultiIndex Series where:\n",
    "    # Level 1 = Region\n",
    "    # Level 2 = City\n",
    "# ‚Üí Each combination has an aggregated value.\n",
    "df_grouped = df.groupby(['Region', 'City'])['Sales'].sum()\n",
    "df_grouped_index_resetted = df.groupby(['Region', 'City'])['Sales'].sum().reset_index() \n",
    "df_grouped_index_resetted\n",
    "\n",
    "# Applying Multiple Aggregations (agg)\n",
    "df.groupby(['Region', 'City'])['Sales'].agg(['sum', 'min', 'max']).reset_index() \n",
    "\n",
    "\n",
    "# Applying Custom Functions in GroupBy\n",
    "def my_range(series):\n",
    "    return series.max() - series.min()\n",
    "\n",
    "df.groupby('Region')['Sales'].agg(['sum', 'mean', my_range])\n",
    "\n",
    "# You can also give it a custom name\n",
    "result = df.groupby('Region')['Sales'].agg(sum='sum', avg='mean', range=my_range)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e0dfbac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>City</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Name_split</th>\n",
       "      <th>Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Smith</td>\n",
       "      <td>Cairo</td>\n",
       "      <td>John</td>\n",
       "      <td>Smith</td>\n",
       "      <td>[John, Smith]</td>\n",
       "      <td>John Smith from Cairo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice Johnson</td>\n",
       "      <td>London</td>\n",
       "      <td>Alice</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>[Alice, Johnson]</td>\n",
       "      <td>Alice Johnson from London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bob Davis</td>\n",
       "      <td>new york</td>\n",
       "      <td>Bob</td>\n",
       "      <td>Davis</td>\n",
       "      <td>[Bob, Davis]</td>\n",
       "      <td>Bob Davis from new york</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Cena</td>\n",
       "      <td>Paris</td>\n",
       "      <td>John</td>\n",
       "      <td>Cena</td>\n",
       "      <td>[John, Cena]</td>\n",
       "      <td>John Cena from Paris</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name      City First Name Last Name        Name_split  \\\n",
       "0     John Smith     Cairo       John     Smith     [John, Smith]   \n",
       "1  Alice Johnson    London      Alice   Johnson  [Alice, Johnson]   \n",
       "2      Bob Davis  new york        Bob     Davis      [Bob, Davis]   \n",
       "3      John Cena     Paris       John      Cena      [John, Cena]   \n",
       "\n",
       "                        Full  \n",
       "0      John Smith from Cairo  \n",
       "1  Alice Johnson from London  \n",
       "2    Bob Davis from new york  \n",
       "3       John Cena from Paris  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Working with Text Data (.str functions)\n",
    "# Pandas provides powerful string handling functions via .str that work on Series containing text.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': [' Alice ', 'BOB', 'CharLie', None],\n",
    "    'City': ['Cairo', 'London', 'new york', 'Paris']\n",
    "})\n",
    "\n",
    "df['Name'] = df['Name'].str.strip()        # Remove spaces\n",
    "df['Name'] = df['Name'].str.lower()        # To lowercase\n",
    "df['Name'] = df['Name'].str.upper()        # To uppercase\n",
    "df['City'] = df['City'].str.lower()        # convert to lowercase\n",
    "df['City'] = df['City'].str.title()        # Capitalize each word\n",
    "\n",
    "# String Searching & Matching\n",
    "# shows True/False values for each row on the column that matching the condition\n",
    "name = df['Name'].str.contains('ali', case=False, na=False)  # Case insensitive , not null\n",
    "name = df['Name'].str.startswith('A')  \n",
    "city = df['City'].str.endswith('n')\n",
    "# shows the row itself that matching the condition\n",
    "df[df['City'].str.startswith('C')]\n",
    "\n",
    "# String Replace & Extract\n",
    "\n",
    "# regex=False (literal string)\n",
    "df['City'] = df['City'].str.replace('new york', 'NEW YORK', case=False, regex=False)  \n",
    "\n",
    "# regex=True (regex pattern)\n",
    "df['City'] = df['City'].str.replace('new.*', 'NEW YORK', case=False, regex=True)\n",
    "# if you set regex=True and old='new.*', the replacement will occur for strings like 'new york', 'new jersey', 'new mexico', etc. because the regex pattern new.* matches any string that starts with 'new' followed by any characters.\n",
    "# What happens when regex=False? If regex=False (which is the default), the old parameter is treated as a literal string. This means that the replacement will occur only if the string matches the exact literal string.\n",
    "\n",
    "\n",
    "# The .str.extract() method is used to extract substrings from a pandas Series (in this case, df['Name']) using regular expressions.\n",
    "# The expand=False parameter means that the extracted values will be returned as a Series with a single column, rather than expanding the result into multiple columns.\n",
    "df['initial'] = df['Name'].str.extract(r'(^[A-Z])', expand=False)\n",
    "\n",
    "# Extracting multiple substrings\n",
    "df = pd.DataFrame({\n",
    "        'Name': ['John Smith', 'Alice Johnson', 'Bob Davis', 'John Cena'], \n",
    "        'City': ['Cairo', 'London', 'new york', 'Paris']\n",
    "    })\n",
    "\n",
    "# Extract first and last names using regular expressions\n",
    "# The regular expression pattern r'([A-Z][a-z]+)\\s+([A-Z][a-z]+)' is applied to each string in df['Name'].\n",
    "# The pattern consists of two capture groups:\n",
    "# ([A-Z][a-z]+) matches the first name (one uppercase letter followed by one or more lowercase letters).\n",
    "# ([A-Z][a-z]+) matches the last name (one uppercase letter followed by one or more lowercase letters).\n",
    "# The \\s+ matches one or more whitespace characters between the first and last names.\n",
    "# The expand=True parameter returns a DataFrame with multiple columns, where each column corresponds to a capture group in the regular expression pattern.\n",
    "# If a string does not match the regular expression pattern, the resulting values will be NaN (Not a Number).\n",
    "df[['First Name', 'Last Name']] = df['Name'].str.extract(r'([A-Z][a-z]+)\\s+([A-Z][a-z]+)', expand=True)\n",
    "\n",
    "df['Name_split'] = df['Name'].str.split()   # return array\n",
    "df['Name'].str.split().str[0]   # return series of the first word of each array\n",
    "\n",
    "# Joining text:\n",
    "df['Full'] = df['Name'] + ' from ' + df['City']\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3b46f35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Categorical Data\n",
    "\n",
    "\"\"\"\n",
    "Goal: Optimize memory and speed when working with repeated string values.\n",
    "\n",
    "What is Categorical Data?\n",
    "    Regular object/string columns in Pandas take more memory and are slower when they have repetitive values.\n",
    "\n",
    "You can convert them to category type to:\n",
    "‚úÖ Save memory\n",
    "‚úÖ Speed up filtering & grouping\n",
    "\"\"\"\n",
    "\n",
    "# Converting to Category\n",
    "df = pd.DataFrame({\n",
    "    'City': ['Cairo', 'London', 'Cairo', 'Paris', 'Cairo', 'London']\n",
    "})\n",
    "\n",
    "# Before: object dtype\n",
    "df.dtypes\n",
    "\n",
    "# convert to category\n",
    "df['City'] = df['City'].astype('category')\n",
    "\n",
    "# After: category dtype\n",
    "df.dtypes\n",
    "\n",
    "# Memory Comparison\n",
    "\"\"\"\n",
    "df.memory_usage(deep=True) is a pandas function that returns the memory usage of a DataFrame, including the memory usage of the values in the DataFrame.\n",
    "\n",
    "Here's a breakdown of what it does:\n",
    "\n",
    "df.memory_usage(): This function returns the memory usage of a DataFrame in bytes. It includes the memory usage of the index, columns, and data.\n",
    "deep=True: This parameter tells pandas to also include the memory usage of the values in the DataFrame, not just the metadata (index, columns, etc.). This means that it will recursively calculate the memory usage of any object that is stored in the DataFrame, such as strings, lists, or other DataFrames.\n",
    "By setting deep=True, you get a more accurate estimate of the total memory usage of the DataFrame, including the memory used by the data itself.\n",
    "\"\"\"\n",
    "df.memory_usage(deep=True)\n",
    "\n",
    "# Working with Categorical Columns\n",
    "df['City'].cat.categories   # See unique categories\n",
    "\n",
    "# category codes\n",
    "\"\"\"\n",
    "- What are categorical codes?\n",
    "The integer numbers assigned to each unique value of the category column which are not entirely random, but rather, they are assigned in a specific order based on the order of the unique values in the column.\n",
    "\n",
    "When you create a categorical data type, pandas assigns a unique integer code to each unique value in the column, starting from 0. The codes are assigned in the order of the unique values, so the first unique value gets code 0, the second unique value gets code 1, and so on.\n",
    "\n",
    "For example, if the 'City' column has the following unique values:\n",
    "\n",
    "'New York'\n",
    "'Chicago'\n",
    "'San Francisco'\n",
    "The categorical codes might be:\n",
    "\n",
    "'New York': 0\n",
    "'Chicago': 1\n",
    "'San Francisco': 2\n",
    "You can then use these codes to access the corresponding values in the column. For example, df['City'].cat.codes == 0 would select all rows where the 'City' column is 'New York'.\n",
    "\n",
    "You can perform various operations on the categorical codes, such as:\n",
    "\n",
    "Filtering: df[df['City'].cat.codes == 0]\n",
    "Grouping: df.groupby(df['City'].cat.codes).sum()\n",
    "Merging: pd.merge(df, other_df, on='City', how='left')\n",
    "\n",
    "\n",
    "- Why are categorical codes used?\n",
    "\n",
    "Categorical codes are used to:\n",
    "\n",
    "Reduce memory usage: Storing categorical data as integers can be more memory-efficient than storing the original string values.\n",
    "Improve performance: Categorical codes can be faster to process than string values in certain operations, such as grouping and aggregating.\n",
    "Enable categorical operations: Categorical codes can be used to perform operations that are specific to categorical data, such as grouping and aggregating.\n",
    "\n",
    "- How are categorical codes created?\n",
    "\n",
    "Categorical codes are created when you convert a column to a categorical data type using the astype('category')\n",
    "\"\"\"\n",
    "df['City'].cat.codes\n",
    "\n",
    "\n",
    "# rename categories\n",
    "df['City'] = df['City'].cat.rename_categories({'Cairo': 'CAI', 'London': 'LDN', 'Paris': 'PAR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b104ae2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>rolling_average</th>\n",
       "      <th>expanding_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-01-01</th>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-02</th>\n",
       "      <td>20</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-03</th>\n",
       "      <td>15</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-04</th>\n",
       "      <td>30</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>18.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-05</th>\n",
       "      <td>45</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-06</th>\n",
       "      <td>40</td>\n",
       "      <td>38.333333</td>\n",
       "      <td>26.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-07</th>\n",
       "      <td>35</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>27.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-08</th>\n",
       "      <td>50</td>\n",
       "      <td>41.666667</td>\n",
       "      <td>30.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-09</th>\n",
       "      <td>55</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-10</th>\n",
       "      <td>60</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sales  rolling_average  expanding_mean\n",
       "Date                                              \n",
       "2024-01-01     10              NaN       10.000000\n",
       "2024-01-02     20        15.000000       15.000000\n",
       "2024-01-03     15        15.000000       15.000000\n",
       "2024-01-04     30        21.666667       18.750000\n",
       "2024-01-05     45        30.000000       24.000000\n",
       "2024-01-06     40        38.333333       26.666667\n",
       "2024-01-07     35        40.000000       27.857143\n",
       "2024-01-08     50        41.666667       30.625000\n",
       "2024-01-09     55        46.666667       33.333333\n",
       "2024-01-10     60        55.000000       36.000000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Window Functions & Rolling\n",
    "\"\"\"\n",
    "Perform calculations over a moving window across your data (instead of over the entire dataset).\n",
    "\n",
    "Instead of calculating one global value (like .mean()), you calculate it locally over rolling chunks of the data.\n",
    "\n",
    "Useful for:\n",
    "\n",
    "    Moving averages\n",
    "\n",
    "    Running totals\n",
    "\n",
    "    Rolling statistics (min, max, std, etc.)\n",
    "\"\"\"\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Date': pd.date_range(start='2024-01-01', periods=10, freq='D'),\n",
    "    'Sales': [10, 20, 15, 30, 45, 40, 35, 50, 55, 60]\n",
    "})\n",
    "\n",
    "df = df.set_index('Date')\n",
    "df['rolling_average'] = df['Sales'].rolling(window=3).mean()  \n",
    "# For each row ‚Üí take current value + previous 2 ‚Üí compute mean.\n",
    "# üëâ First two rows = NaN (not enough previous data).\n",
    "\n",
    "\n",
    "df['expanding_mean'] = df['Sales'].expanding().mean()  # Useful for cumulative averages (each point sees all previous points).\n",
    "\n",
    "\"\"\"\n",
    "When you set window=3 and min_periods=2, you're telling pandas to:\n",
    "\n",
    "- Calculate the rolling average using a window of 3 numbers (i.e., the current number and the 2 preceding numbers).\n",
    "- But, if there are only 2 numbers available (i.e., the current number and only 1 preceding number), still calculate the average using those 2 numbers.\n",
    "\n",
    "In other words, min_periods=2 overrides the window=3 requirement, allowing the calculation to proceed even if there aren't enough numbers to fill the entire window.\n",
    "\n",
    "By doing so, you'll get a result for the rolling average even when there are only 2 numbers available, instead of getting NaN (Not a Number).\n",
    "\"\"\"\n",
    "df['rolling_average'] = df['Sales'].rolling(window=3, min_periods=2).mean()  \n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d8e41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>Quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>78</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  UnitPrice  Quantity\n",
       "1      Bob         90        10\n",
       "2  Charlie         78        10"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Performance & Optimization\n",
    "# Write faster, more memory-efficient Pandas code, especially when dealing with big DataFrames.\n",
    "\n",
    "# Memory Optimization\n",
    "\n",
    "# 1. Use category for Repeated Text: Cuts memory when the same string appears often.\n",
    "\"\"\"\n",
    "In the context of pandas, \"cuts memory\" means that using categorical data types for repeated text can reduce the amount of memory required to store the data.\n",
    "\n",
    "When you have a column with repeated text values, pandas stores each value as a separate string object in memory. This can lead to a significant amount of memory usage, especially if the column contains many repeated values.\n",
    "\n",
    "By converting the column to a categorical data type, pandas can store the repeated values more efficiently. Here's how it works:\n",
    "\n",
    "Unique values are stored separately: pandas stores the unique values in the column as a separate array, which is typically much smaller than the original column.\n",
    "Integer codes are used to represent values: pandas assigns an integer code to each unique value in the array. These codes are used to represent the values in the original column.\n",
    "Codes are stored in the original column: The integer codes are stored in the original column, replacing the original text values.\n",
    "\n",
    "df['City'] = df['City'].astype('category')\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 2. Downcast Numeric Types\n",
    "\"\"\"\n",
    "Downcasting refers to the process of converting a column's data type to a smaller, more memory-efficient type, without losing significant data precision. This is particularly useful when working with large datasets to reduce memory usage.\n",
    "\n",
    "df['Sales'].dtypes  # int64\n",
    "\n",
    "df['Sales'] = pd.to_numeric(df['Sales'], downcast='integer')  # Changes int64 ‚Üí int8 / int16 to save space.\n",
    "\n",
    "df.dtypes   # int8\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# 3. Check Memory Usage\n",
    "\n",
    "\"\"\"\n",
    "df.info(memory_usage='deep')\n",
    "\n",
    "This line displays a concise summary of the DataFrame, including the memory usage of each column. The memory_usage='deep' parameter tells pandas to include the memory usage of the values in the DataFrame, not just the metadata (e.g., column names, data types).\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "df.memory_usage(deep=True)\n",
    "\n",
    "This line returns a Series that shows the memory usage of each column in the DataFrame, including the memory usage of the values. The deep=True parameter tells pandas to include the memory usage of the values in the DataFrame, not just the metadata.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Speed Optimization\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'UnitPrice': [85, 90, 78],\n",
    "    'Quantity': [5, 10, 10]\n",
    "})\n",
    "\n",
    "# 1. Vectorized Operations\n",
    "\"\"\"\n",
    "Always prefer:\n",
    "`\n",
    "    df['Price'] = df['Quantity'] * df['UnitPrice']  # Fast ‚Üí no loops\n",
    "`\n",
    "instead of:\n",
    "`\n",
    "    for i in df.index:\n",
    "        df.loc[i, 'Price'] = df.loc[i, 'Quantity'] * df.loc[i, 'UnitPrice']\n",
    "\n",
    "`\n",
    "and they have the same result\n",
    "\"\"\"\n",
    "\n",
    "# 2. Avoid .apply() unless really needed\n",
    "\"\"\"\n",
    "you can use:\n",
    "`\n",
    "    df['Quantity'] = df['Quantity'] + 10\n",
    "`\n",
    "instead of:\n",
    "`\n",
    "    df['Quantity'] = df['Quantity'].apply(lambda x: x + 10)\n",
    "\n",
    "`\n",
    "and they have the same result\n",
    "\"\"\"\n",
    "\n",
    "# 3. Use query() for Faster Filtering\n",
    "df.query('Quantity > 5 and UnitPrice > 30')  # Faster and more readable than chaining multiple conditions with []\n",
    "\n",
    "\n",
    "# Use Chunking for Very Large Files\n",
    "\"\"\"\n",
    "for chunk in pd.read_csv('large_file.csv', chunksize=10000):\n",
    "    process(chunk)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Parallelism with Dask (Optional)\n",
    "\"\"\"\n",
    "# Syntax is nearly identical to Pandas but runs in parallel.\n",
    "\n",
    "import dask.dataframe as dd\n",
    "ddf = dd.read_csv('very_large.csv')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
